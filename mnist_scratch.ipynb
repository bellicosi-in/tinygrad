{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39a3d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyanshukumar/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6859f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch(url):\n",
    "#     import requests, os, gzip, hashlib, numpy as np  # Changed numpy import alias for consistency\n",
    "#     fp = os.path.join(\"/tmp\", hashlib.md5(url.encode('utf-8')).hexdigest())\n",
    "    \n",
    "#     if os.path.isfile(fp):  # Check if file exists\n",
    "#         with open(fp, \"rb\") as f:\n",
    "#             dat = f.read()\n",
    "#     else:  # If not, fetch and write to file\n",
    "#         with open(fp, \"wb\") as f:\n",
    "#             dat = requests.get(url).content\n",
    "#             f.write(dat)\n",
    "    \n",
    "#     return np.frombuffer(gzip.decompress(dat), dtype=np.uint8)  # Return statement outside of the if-else block\n",
    "\n",
    "# # Fetch the MNIST dataset\n",
    "# X_train = fetch(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")\n",
    "# Y_train = fetch(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\")\n",
    "# X_test = fetch(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\")\n",
    "# Y_test = fetch(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\")\n",
    "\n",
    "\n",
    "# import os,gzip,numpy as np\n",
    "# fp = os.path.join(\"/Users/priyanshukumar/Desktop/fafi/tinygrad/archive (1)/train-images.idx3-ubyte\")\n",
    "# with open(fp, \"rb\") as f:\n",
    "#     dat = f.read()\n",
    "\n",
    "import os,numpy as np,hashlib\n",
    "def file_read(path):\n",
    "    fp = os.path.join(path)\n",
    "    if os.path.isfile(fp):\n",
    "        with open(fp,\"rb\") as f:\n",
    "            dat = f.read()\n",
    "    else:\n",
    "        with open(fp,\"wb\") as f:\n",
    "            dat = f.write()\n",
    "            \n",
    "    return np.frombuffer(dat,dtype = np.uint8).copy()\n",
    "X_train = file_read(\"/Users/priyanshukumar/Desktop/fafi/tinygrad/archive (1)/train-images.idx3-ubyte\")[0x10:].reshape((-1,28,28))\n",
    "Y_train = file_read(\"/Users/priyanshukumar/Desktop/fafi/tinygrad/archive (1)/train-labels.idx1-ubyte\")[8:]\n",
    "X_test =  file_read(\"/Users/priyanshukumar/Desktop/fafi/tinygrad/archive (1)/t10k-images.idx3-ubyte\")[0x10:].reshape((-1,28,28))\n",
    "Y_test =  file_read(\"/Users/priyanshukumar/Desktop/fafi/tinygrad/archive (1)/t10k-labels.idx3-ubyte\")[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a729935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(-1,28*28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08a5eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2eebbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RandNet,self).__init__()\n",
    "        self.l1 = nn.Linear(784,128)\n",
    "        self.act = nn.ReLU()\n",
    "        self.l2 = nn.Linear(128,10)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = RandNet()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ef459ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.6635, grad_fn=<NllLossBackward0>)\n",
      "tensor(30.4193, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.9449, grad_fn=<NllLossBackward0>)\n",
      "tensor(14.5114, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.3646, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5762, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.9863, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2031, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.3525, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5955, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3382, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3448, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0420, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2486, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6208, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2810, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5018, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "for i in range(20):\n",
    "    \n",
    "    samp = np.random.randint(0,X_train.shape[0],size=(bs))\n",
    "    X = torch.tensor(X_train[samp].reshape((-1, 28*28))).float()\n",
    "    Y = torch.tensor(Y_train[samp]).long()\n",
    "    optim.zero_grad()\n",
    "    out = model(X)\n",
    "    loss = loss_func(out,Y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3f6a1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 22904\r\n",
      "drwxr-xr-x  11 priyanshukumar  staff       352 Apr 30 21:17 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   4 priyanshukumar  staff       128 Apr 30 16:14 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 priyanshukumar  staff      6148 Apr 30 16:14 .DS_Store\r\n",
      "drwxr-xr-x   3 priyanshukumar  staff        96 Apr 30 21:17 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 priyanshukumar  staff         0 Apr 30 16:57 69d73ec0b36c2d30f661afebde96e22b\r\n",
      "-rw-r--r--   1 priyanshukumar  staff         0 Apr 30 17:02 97553ff1ae57930259f7353883645639\r\n",
      "drwx------@ 12 priyanshukumar  staff       384 Apr 30 16:47 \u001b[34marchive (1)\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 priyanshukumar  staff         0 Apr 30 17:00 ed8812f41a50b0d4b2eddaa16b4ecbc1\r\n",
      "-rw-r--r--   1 priyanshukumar  staff         0 Apr 30 17:00 f1f146931e8e49420b4342a8389dab3f\r\n",
      "-rw-r--r--@  1 priyanshukumar  staff  11707367 Apr 30 16:19 mnist.hdf5\r\n",
      "-rw-r--r--   1 priyanshukumar  staff      6817 Apr 30 17:38 mnist_scratch.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git init\n",
    "!git add mnis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
